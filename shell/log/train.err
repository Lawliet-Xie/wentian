+ cd /public/home/yuqi/lawliet/nlp/wentian/shell
+ date
+ hostname
+ nvidia-smi
+ CUDA_VISIBLE_DEVICES=1
+ /public/home/yuqi/anaconda3/bin/python3 /public/home/yuqi/lawliet/nlp/wentian/train_hard.py
Some weights of the model checkpoint at /public/home/yuqi/lawliet/nlp/wentian/cache/chinese-roberta-wwm-ext/ were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight']
- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
